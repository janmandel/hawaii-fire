{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dca7608-6fa4-4d50-b58e-adee84312e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The neccessary packages\n",
    "## In-house packages\n",
    "from saveload import save,load\n",
    "from ml_sample_generator import load_fire_detection, load_topography\n",
    "## Pacakages from anywhere else\n",
    "import os\n",
    "from os import path as osp \n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol, xy\n",
    "from pyproj import CRS, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6187d248-2240-41d6-a8fb-66b8c879aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file paths\n",
    "tif = osp.join('C:/', 'Users', 'T-Spe', 'OneDrive', 'School', \"Fall '25\", \"Master's Project\", 'test')\n",
    "local = osp.join('C:/', 'Users', 'T-Spe', 'Downloads')\n",
    "\n",
    "file_paths = {\"elevation_path\": osp.join(tif ,'LH20_Elev_220.tif'),\n",
    "            \"slope_path\": osp.join(tif, 'LH20_SlpP_220.tif'),\n",
    "            \"aspect_path\": osp.join(tif, 'LH20_Asp_220.tif'),\n",
    "            #\"process_path\": osp.join(local, 'processed_output.nc'),\n",
    "            \"fire_path\": osp.join(local,'ml_data'),\n",
    "            \"nc_output_path\": osp.join(local, 'row_col_mask.nc') \n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daabdae0-99bc-4ee4-9b22-c0fef77aae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_with_row_col_and_mask(\n",
    "    lon_array,\n",
    "    lat_array,\n",
    "    raster_crs,\n",
    "    transform,\n",
    "    raster_shape,\n",
    "    output_file,\n",
    "    debug=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a NetCDF file with row, column indices, and a spatial mask for provided lon/lat data.\n",
    "    \n",
    "    Args:\n",
    "        lon_array (np.ndarray): Array of longitudes in WGS84.\n",
    "        lat_array (np.ndarray): Array of latitudes in WGS84.\n",
    "        raster_crs (str): CRS of the raster (e.g., \"EPSG:5070\").\n",
    "        transform (Affine): Rasterio affine transform of the raster.\n",
    "        raster_shape (tuple): Shape of the raster (rows, cols).\n",
    "        output_file (str): Path to the output NetCDF file.\n",
    "        debug (bool): Whether to enable debug messages.\n",
    "    \"\"\"\n",
    "    print(f\"Creating NetCDF file at {output_file}...\")\n",
    "\n",
    "    # Initialize transformer\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Reproject lon/lat to raster CRS\n",
    "    print(\"Transforming coordinates to raster CRS...\")\n",
    "    raster_lon, raster_lat = transformer.transform(lon_array, lat_array)\n",
    "\n",
    "    # Calculate row and column indices\n",
    "    inv_transform = ~transform\n",
    "    cols, rows = inv_transform * (raster_lon, raster_lat)\n",
    "\n",
    "    # Round indices and convert to integers\n",
    "    rows = np.round(rows).astype(int)\n",
    "    cols = np.round(cols).astype(int)\n",
    "\n",
    "    # Create a valid mask based on raster shape\n",
    "    valid_mask = (\n",
    "        (rows >= 0) & (rows < raster_shape[0]) &\n",
    "        (cols >= 0) & (cols < raster_shape[1])\n",
    "    )\n",
    "    rows_valid = rows[valid_mask]\n",
    "    cols_valid = cols[valid_mask]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Valid row indices: {rows_valid}\")\n",
    "        print(f\"Valid col indices: {cols_valid}\")\n",
    "        print(f\"Valid mask shape: {valid_mask.shape}\")\n",
    "        print(f\"Number of valid points: {np.sum(valid_mask)}\")\n",
    "\n",
    "    # Write to NetCDF\n",
    "    with Dataset(output_file, 'w', format='NETCDF4') as nc_file:\n",
    "        # Define dimensions\n",
    "        nc_file.createDimension('points', len(rows_valid))\n",
    "        nc_file.createDimension('mask', len(valid_mask))\n",
    "\n",
    "        # Create variables\n",
    "        rows_var = nc_file.createVariable('rows', 'i4', ('points',), zlib=True)\n",
    "        cols_var = nc_file.createVariable('cols', 'i4', ('points',), zlib=True)\n",
    "        mask_var = nc_file.createVariable('valid_mask', 'i1', ('mask',), zlib=True)\n",
    "\n",
    "        # Write data\n",
    "        rows_var[:] = rows_valid\n",
    "        cols_var[:] = cols_valid\n",
    "        mask_var[:] = valid_mask.astype(int)\n",
    "\n",
    "    print(f\"NetCDF file saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d5091aa-bece-4b60-9bfc-f82213c85843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_row_col(rows, cols, raster_crs, transform):\n",
    "    \"\"\"\n",
    "    Validate the row and column indices by reprojecting them back to longitude and latitude.\n",
    "\n",
    "    Args:\n",
    "        rows (np.ndarray): Array of row indices.\n",
    "        cols (np.ndarray): Array of column indices.\n",
    "        raster_crs (str): CRS of the raster (e.g., \"EPSG:5070\").\n",
    "        transform (Affine): Rasterio affine transform of the raster.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Reprojected longitude and latitude arrays.\n",
    "    \"\"\"\n",
    "    print(\"Validating row and column indices by reprojecting back to longitude and latitude...\")\n",
    "\n",
    "    # Use rasterio's transform to compute the coordinates\n",
    "    raster_coords = xy(transform, rows, cols, offset='center')\n",
    "\n",
    "    # Extract the projected coordinates\n",
    "    raster_x, raster_y = raster_coords\n",
    "\n",
    "     # Step 2: Reproject from the raster CRS to WGS84\n",
    "    transformer = Transformer.from_crs(raster_crs, \"EPSG:4326\", always_xy=True)\n",
    "    lon_wgs84, lat_wgs84 = transformer.transform(raster_x, raster_y)\n",
    "\n",
    "    #print(f\"First 10 Reprojected WGS84 Longitudes: {lon_wgs84[:10]}\")\n",
    "    #print(f\"First 10 Reprojected WGS84 Latitudes: {lat_wgs84[:10]}\")\n",
    "\n",
    "    # Verify if any NaN or invalid values exist\n",
    "    if np.isnan(lon_wgs84).any() or np.isnan(lat_wgs84).any():\n",
    "        raise ValueError(\"Reprojected coordinates contain NaN values.\")\n",
    "\n",
    "    return lon_wgs84, lat_wgs84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a29fde0-d537-4213-b35b-2280f8b14bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hardcoded time bounds: time_lb = 2011-01-02 00:00:00, time_ub = 2024-09-14 23:00:00\n",
      "Loading topography data...\n",
      "Trying to open C:/Users\\T-Spe\\OneDrive\\School\\Fall '25\\Master's Project\\test\\LH20_Elev_220.tif as <open DatasetReader name='C:/Users\\T-Spe\\OneDrive\\School\\Fall '25\\Master's Project\\test\\LH20_Elev_220.tif' mode='r'>\n",
      "Loading fire detection data...\n",
      "Total data points: 267414861\n",
      "Number of 'Fire' labels: 43852\n",
      "Number of 'Fire' labels with confidence < 70: 10474\n",
      "Number of remaining data points: 265165164\n",
      "Number of remaining 'Fire' labels: 33337\n",
      "Loaded 267414861 data points, filtered down to 265165164 based on confidence and labels.\n"
     ]
    }
   ],
   "source": [
    "# Hardcoding time bounds to avoid loading meteorology data\n",
    "# Dataset times are confirmed as: 2011-01-02 00:00:00 to 2024-09-14 23:00:00\n",
    "# Hardcoded time bounds\n",
    "time_lb = pd.Timestamp(\"2011-01-02 00:00:00\")\n",
    "time_ub = pd.Timestamp(\"2024-09-14 23:00:00\")\n",
    "\n",
    "print(f\"Using hardcoded time bounds: time_lb = {time_lb}, time_ub = {time_ub}\")\n",
    "\n",
    "# Load topography data\n",
    "topography = load_topography(file_paths)\n",
    "raster_crs =topography[\"crs\"]\n",
    "transform = topography[\"transform\"]\n",
    "raster_shape = topography[\"elevation\"].shape\n",
    "\n",
    "# Load and filter fire detection data\n",
    "fire_detection_data = load_fire_detection(file_paths, time_lb, time_ub, confidence_threshold =70)\n",
    "lon_array = fire_detection_data['lon']\n",
    "lat_array = fire_detection_data['lat']\n",
    "#dates_fire = fire_detection_data['dates_fire']\n",
    "#labels = fire_detection_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8099f4c5-305a-40f5-83b6-f0408854f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NetCDF file at C:/Users\\T-Spe\\Downloads\\row_col_mask.nc...\n",
      "Transforming coordinates to raster CRS...\n",
      "Valid row indices: [   1    0    8 ... 1471 1477 1460]\n",
      "Valid col indices: [4528 4093 4165 ... 1149 1197 1174]\n",
      "Valid mask shape: (265165164,)\n",
      "Number of valid points: 229300941\n",
      "NetCDF file saved: C:/Users\\T-Spe\\Downloads\\row_col_mask.nc\n"
     ]
    }
   ],
   "source": [
    "output_netcdf = file_paths[\"nc_output_path\"]\n",
    "debug = True\n",
    "\n",
    "# Call the function to create the saved file with row, col indices, and mask for spatial points outside of raster\n",
    "# NOTE: The saved file is there so this block does not need to be ran again.\n",
    "create_netcdf_with_row_col_and_mask(\n",
    "    lon_array,\n",
    "    lat_array,\n",
    "    raster_crs,\n",
    "    transform,\n",
    "    raster_shape,\n",
    "    output_netcdf,\n",
    "    debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240d4746-a5cc-49ce-86ad-6616b859ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the mask array is: (265165164,)\n",
      "The shape of the row array is: (229300941,)\n",
      "The shape of the column array is: (229300941,)\n",
      "Mask min: 0, Mask max: 1\n",
      "Mask contains NaNs: False\n",
      "Mask contains None: False\n",
      "Rows min: 0, Rows max: 5257\n",
      "Rows contains NaNs: False\n",
      "Rows contains None: False\n",
      "Columns min: 0, Columns max: 4609\n",
      "Columns contain NaNs: False\n",
      "Columns contain None: False\n"
     ]
    }
   ],
   "source": [
    "# Read the saved test file, check the shapes and minor data exploration\n",
    "row_col_data = Dataset(output_netcdf)\n",
    "\n",
    "# Check shapes\n",
    "mask_shape = row_col_data.variables['valid_mask'][:].shape\n",
    "rows_shape = row_col_data.variables['rows'][:].shape\n",
    "cols_shape = row_col_data.variables['cols'][:].shape\n",
    "\n",
    "print(f\"The shape of the mask array is: {mask_shape}\")\n",
    "print(f\"The shape of the row array is: {rows_shape}\")\n",
    "print(f\"The shape of the column array is: {cols_shape}\")\n",
    "\n",
    "# Check min, max, and NaN values for 'valid_mask'\n",
    "valid_mask = row_col_data.variables['valid_mask'][:]\n",
    "print(f\"Mask min: {valid_mask.min()}, Mask max: {valid_mask.max()}\")\n",
    "print(f\"Mask contains NaNs: {np.isnan(valid_mask).any()}\")\n",
    "print(f\"Mask contains None: {np.any(valid_mask == None)}\")  # NaNs should suffice, but adding for clarity\n",
    "\n",
    "# Check min, max, and NaN values for 'rows'\n",
    "rows = row_col_data.variables['rows'][:]\n",
    "print(f\"Rows min: {rows.min()}, Rows max: {rows.max()}\")\n",
    "print(f\"Rows contains NaNs: {np.isnan(rows).any()}\")\n",
    "print(f\"Rows contains None: {np.any(rows == None)}\")\n",
    "\n",
    "# Check min, max, and NaN values for 'cols'\n",
    "cols = row_col_data.variables['cols'][:]\n",
    "print(f\"Columns min: {cols.min()}, Columns max: {cols.max()}\")\n",
    "print(f\"Columns contain NaNs: {np.isnan(cols).any()}\")\n",
    "print(f\"Columns contain None: {np.any(cols == None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad7c3b4-b881-4501-b9ae-c3a23f069930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating row and column indices by reprojecting back to longitude and latitude...\n",
      "Max Longitude Difference: 0.00028825367053286755\n",
      "Max Latitude Difference: 0.00027203518735774423\n"
     ]
    }
   ],
   "source": [
    "# Reproject the (row,col) back to (lon, lat) and compare to (lon, lat) used to obtain (row, col)\n",
    "valid_mask = row_col_data.variables['valid_mask'][:].astype(bool)\n",
    "lon_array_valid = lon_array[valid_mask]\n",
    "lat_array_valid = lat_array[valid_mask]\n",
    "\n",
    "lon_reproj_row , lat_reproj_col = validate_row_col(rows, cols, raster_crs, transform)\n",
    "\n",
    "diff_lon = np.abs(lon_reproj_row - lon_array_valid)\n",
    "diff_lat = np.abs(lat_reproj_col - lat_array_valid)\n",
    "print(f\"Max Longitude Difference: {np.max(diff_lon)}\")\n",
    "print(f\"Max Latitude Difference: {np.max(diff_lat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
