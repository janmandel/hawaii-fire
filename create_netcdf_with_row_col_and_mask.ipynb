{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dca7608-6fa4-4d50-b58e-adee84312e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path as osp \n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as NC\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from saveload import save,load\n",
    "from ml_sample_generator import load_fire_detection, load_topography, load_meteorology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6187d248-2240-41d6-a8fb-66b8c879aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file paths\n",
    "tif = osp.join('C:/', 'Users', 'T-Spe', 'OneDrive', 'School', \"Fall '25\", \"Master's Project\", 'test')\n",
    "local = osp.join('C:/', 'Users', 'T-Spe', 'Downloads')\n",
    "\n",
    "file_paths = {\"elevation_path\": osp.join(tif ,'LH20_Elev_220.tif'),\n",
    "            \"slope_path\": osp.join(tif, 'LH20_SlpP_220.tif'),\n",
    "            \"aspect_path\": osp.join(tif, 'LH20_Asp_220.tif'),\n",
    "            \"process_path\": osp.join(local, 'processed_output.nc'),\n",
    "            \"fire_path\": osp.join(local,'ml_data')\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daabdae0-99bc-4ee4-9b22-c0fef77aae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_with_row_col_and_mask(\n",
    "    lon_array,\n",
    "    lat_array,\n",
    "    raster_crs,\n",
    "    transform,\n",
    "    raster_shape,\n",
    "    output_file,\n",
    "    debug=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a NetCDF file with row, column indices, and a spatial mask for provided lon/lat data.\n",
    "    \n",
    "    Args:\n",
    "        lon_array (np.ndarray): Array of longitudes in WGS84.\n",
    "        lat_array (np.ndarray): Array of latitudes in WGS84.\n",
    "        raster_crs (str): CRS of the raster (e.g., \"EPSG:5070\").\n",
    "        transform (Affine): Rasterio affine transform of the raster.\n",
    "        raster_shape (tuple): Shape of the raster (rows, cols).\n",
    "        output_file (str): Path to the output NetCDF file.\n",
    "        debug (bool): Whether to enable debug messages.\n",
    "    \"\"\"\n",
    "    print(f\"Creating NetCDF file at {output_file}...\")\n",
    "\n",
    "    # Initialize transformer\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Reproject lon/lat to raster CRS\n",
    "    print(\"Transforming coordinates to raster CRS...\")\n",
    "    raster_lon, raster_lat = transformer.transform(lon_array, lat_array)\n",
    "\n",
    "    # Calculate row and column indices\n",
    "    inv_transform = ~transform\n",
    "    cols, rows = inv_transform * (raster_lon, raster_lat)\n",
    "\n",
    "    # Round indices and convert to integers\n",
    "    rows = np.round(rows).astype(int)\n",
    "    cols = np.round(cols).astype(int)\n",
    "\n",
    "    # Create a valid mask based on raster shape\n",
    "    valid_mask = (\n",
    "        (rows >= 0) & (rows < raster_shape[0]) &\n",
    "        (cols >= 0) & (cols < raster_shape[1])\n",
    "    )\n",
    "    rows_valid = rows[valid_mask]\n",
    "    cols_valid = cols[valid_mask]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Valid row indices: {rows_valid}\")\n",
    "        print(f\"Valid col indices: {cols_valid}\")\n",
    "        print(f\"Valid mask shape: {valid_mask.shape}\")\n",
    "        print(f\"Number of valid points: {np.sum(valid_mask)}\")\n",
    "\n",
    "    # Write to NetCDF\n",
    "    with Dataset(output_file, 'w', format='NETCDF4') as nc_file:\n",
    "        # Define dimensions\n",
    "        nc_file.createDimension('points', len(rows_valid))\n",
    "        nc_file.createDimension('mask', len(valid_mask))\n",
    "\n",
    "        # Create variables\n",
    "        rows_var = nc_file.createVariable('rows', 'i4', ('points',), zlib=True)\n",
    "        cols_var = nc_file.createVariable('cols', 'i4', ('points',), zlib=True)\n",
    "        mask_var = nc_file.createVariable('valid_mask', 'i1', ('mask',), zlib=True)\n",
    "\n",
    "        # Write data\n",
    "        rows_var[:] = rows_valid\n",
    "        cols_var[:] = cols_valid\n",
    "        mask_var[:] = valid_mask.astype(int)\n",
    "\n",
    "    print(f\"NetCDF file saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a29fde0-d537-4213-b35b-2280f8b14bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading topography data...\n",
      "Trying to open C:/Users\\T-Spe\\OneDrive\\School\\Fall '25\\Master's Project\\test\\LH20_Elev_220.tif as <open DatasetReader name='C:/Users\\T-Spe\\OneDrive\\School\\Fall '25\\Master's Project\\test\\LH20_Elev_220.tif' mode='r'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_lb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m topography \u001b[38;5;241m=\u001b[39m load_topography(file_paths)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load and filter fire detection data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m fire_detection_data \u001b[38;5;241m=\u001b[39m load_fire_detection(file_paths, \u001b[43mtime_lb\u001b[49m, time_ub, confidence_threshold)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract relevant data\u001b[39;00m\n\u001b[0;32m     14\u001b[0m lon_array \u001b[38;5;241m=\u001b[39m fire_detection_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time_lb' is not defined"
     ]
    }
   ],
   "source": [
    "# Load meteorology data\n",
    "# meteorology = load_meteorology(file_paths)\n",
    "# time_lb = meteorology['times'].min()\n",
    "# time_ub = meteorology['times'].max()\n",
    "# print(f\"Meteorology time range: {time_lb} to {time_ub}\")\n",
    "\n",
    "# Load topography data\n",
    "topography = load_topography(file_paths)\n",
    "\n",
    "# Load and filter fire detection data\n",
    "fire_detection_data = load_fire_detection(file_paths, time_lb, time_ub, confidence_threshold)\n",
    "\n",
    "# Extract relevant data\n",
    "lon_array = fire_detection_data['lon']\n",
    "lat_array = fire_detection_data['lat']\n",
    "#dates_fire = fire_detection_data['dates_fire']\n",
    "#labels = fire_detection_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099f4c5-305a-40f5-83b6-f0408854f589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
